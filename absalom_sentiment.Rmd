---
title: '*Absalom, Absalom!* Sentiment Analysis'
author: "Johannes Burgers"
output:
  html_document:
    df_print: paged
---


```{r setup, include=FALSE, message = FALSE, warning=FALSE, error=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning=FALSE, error=FALSE)
```

## Introduction

The following is a brief linguistic analysis of the use of racially charged language in William Faulkner's *Absalom, Absalom!*. Faulkner's representation of race was complicated, just as his own his relationship with race was complex. As a Southern white moderate, he voiced his anguish over the dehumanization of African Americans under Jim Crow segregation, and at the same time could also casually refer to people as "niggers" during the public retelling of a [comic story](https://faulkner.lib.virginia.edu/display/wfaudio02_2.html#wfaudio02_2.2). Indeed, there is no shortage of literature on Faulkner and race in general, and with regards to *Absalom, Absalom!* in particular. Given this extensive critical history, it almost goes without saying, that a computational analysis of word choice, especially with regard to racially charged language, cannot due justice to the complexities and nuances of either the text or Faulkner's broader critical intervention. Nevertheless, using techniques common in corpus linguistics (CL) it is possible to give a birds-eye view of how the use of certain words is patterned, this pattern can then, in turn, inform subsequent close readings. 

The following piece uses several techniques available to standard CL analysis, and one more complex analysis that is exclusively available to practitioners who have access to the [Digital Yoknapatawpha](http://faulkner.iath.virginia.edu/) data set. These different techniques have been split into different parts.

- **Part 1: Statistical Overview**  
          Analysis of the general linguistic pattern of the texts including word frequency and word           correlations.
- **Part 2: Sentiment Analysis**  
          Analysis of racially charged language and the sentiments that surround the use of those             words.
- **Part 3: Character Sentiment Analysis**  
          Sentiment analysis of specific characters. Using the data available in the *DY* database,           a sentiment pattern around certain characters was created.
          
All of the data was generated using the R programming language using the `tidyverse` suite of packages. The full repository is available at https://github.com/joostburgers/absalom_sentiment_analysis Due to copyright issues the repository does not include the Absalom, Absalom text file used for data analysis.


## Part 1: Statistical Overview *Absalom, Absalom!*

The text of *Absalom, Absalom!* was read in as a txt file. It was then broken into nine chapters and further sub-setted into sentences. The individual words were subsequently "tokenized." The process of tokenization removes capital letters, special characters, and punctuation. It enables the computer to compare words more easily. Each "stop word" was then removed. These are words like: the, a, on, at, etc. that are very frequent with in any text, and do not add to the analysis. The words were then lemmatized. Lemmatization reduces a word to the word stem. For example, Negroes becomes Negro. This way all instances of the concept "Negro" are unified as one instances. This prevents creating separate counts for words like Negro, Negroes, and Negro's.

The resulting slate of words was then tagged as either racially charged by adding a column called race_word and indicating TRUE or FALSE for each word. This was done by creating a list of racial words and joining it to the data table through a left sided join. Essentially, it checks to see any time a word like "Negro", "Nigger", or "Octoroon" occurs and tags it as TRUE. With this preprocessing complete it is possible to provide some key statistical insights.

### Word Frequency

The chart below shows the ten most frequent non-racial words and racial words in the text. Hovering over the the individual bars reveals their precise number, and clicking on TRUE and FALSE turns that particular series on and off.

```{r load_packages}
library(tidyverse)
library(tidytext)
library(stringi)
library(htmlTable)
library(stringr)
library(ggplot2)
library(plotly)
library(ggthemes)
library(textstem)
```

```{r load_text}
#Read in the text
absalom_df <- as.data.frame(read_file("Faulkner_William_Absalom_Absalom.txt"))
colnames(absalom_df) <- "text" 
```

```{r load_race_words}

race_words <- read_csv("race_words.csv")

```


```{r unnest_text}

#unnest the text by sentence and then label each chapter number and sentence number.
absalom_tidy <- absalom_df %>% 
                unnest_regex(text,text, pattern="—[:digit:]—" ) %>% 
                mutate(chapter = row_number()) %>% 
                unnest_regex(sentences, text, pattern= "[.?!]") %>%
                mutate(sentence_number = row_number())  %>% 
                unnest_tokens(word, sentences)
```

```{r word_frequency}
#Remove the stop words to reduce over counting

data("stop_words")
absalom_stats <- absalom_tidy %>% 
                anti_join(stop_words)  

```


```{r add_race_words}
#Mark each race word as true and then convert every non-race word as false. then add a column for the lemmatized words.

absalom_race_stats <- absalom_stats %>% 
                      mutate(word_lemma = textstem::lemmatize_words(word)) %>% 
                      mutate(word_lemma = str_remove_all(word_lemma,"'s")) %>% 
                     left_join(race_words, by="word_lemma") %>% 
                    mutate(race_word = replace_na(race_word,FALSE))  
                          
```



```{r create_plot}
absalom_plot <- absalom_race_stats %>% 
    group_by(race_word) %>% 
    count(word_lemma, sort = TRUE) %>%
    top_n(10) %>%
    mutate(word_lemma = reorder(word_lemma, n))
```


```{r message=TRUE, results='markup', fig.cap="Note: The chart displays the most frequent words based on word stem.<br> This prevents counting <i>father</i> and <i>father's</i> separately."}

fig <- plot_ly(absalom_plot,
  x = ~word_lemma,
  y = ~n,
  type = "bar",
  color= ~race_word
)

fig <- fig %>% 
        layout(title = "Ten Most Frequent Word by Non-Race and Race Words",
         xaxis = list(title = "Word Stem"),
         yaxis = list(title = "Number of Words"),
              legend=list(title=list(text='<b>Race Word</b>')))

fig

    

```

What is immediately noticeable is that the word "nigger" is the most frequent racial term. It exceeds the word "negro" by 50 counts. It occurs about a third as infrequently as the word Henry (the main character) and twice as infrequently as the racially ambigious Charles Bon. Importantly, the occurrences of the individual names of characters is not the same as the number of times they actually occur in the text. After all, the pronouns "he" or "she" could equally well denote a character, but that is not shown here.

### Collocations


```{r}

#Create a bigram of the Absalom DF
absalom_bigrams <- absalom_df %>%
  unnest_tokens(bigram, text, token = "ngrams", n = 2)

#This function first separates the bigram into two words, lemmatizes each, tags the racial words, then removes all non-racial words. 
race_bigrams <- absalom_bigrams %>%
  separate(bigram, c("word1", "word2"), sep = " ") %>%
  mutate(word_lemma1 = textstem::lemmatize_words(word1)) %>%
  mutate(word_lemma1 = str_remove_all(word_lemma1, "'s")) %>%
  mutate(word_lemma2 = textstem::lemmatize_words(word2)) %>%
  mutate(word_lemma2 = str_remove_all(word_lemma2, "'s")) %>%
  left_join(race_words, by = c("word_lemma1" = "word_lemma")) %>%
  left_join(race_words, by = c("word_lemma2" = "word_lemma"))  %>%
  mutate(race_word = ifelse(race_word.x == TRUE |
                              race_word.y == TRUE, TRUE,
                            ifelse(NA))) %>%
  filter(race_word == TRUE) %>%
  mutate(bigram = paste(word_lemma1, word_lemma2)) %>%
  select (-race_word.x,-race_word.y)

#This function filters all the stop words out of the bigrams

bigrams_filtered <- race_bigrams %>%
  filter(!word1 %in% stop_words$word) %>%
  filter(!word2 %in% stop_words$word)

# new bigram counts:
bigram_counts <- bigrams_filtered %>%
  count(bigram, sort = TRUE) %>% 
  mutate(bigram = reorder(bigram, n)) %>% 
  top_n(15)


```

TODO Explain Cooccurrence


```{r bigram_chart, fig.cap="Note: This plot shows the most common cooccurrence of racial language in Absalom, Absalom!"}


bigram_plot <- plot_ly(bigram_counts,
  x = ~n,
  y = ~bigram,
  type = "bar",
  orientation = 'h'
  )
      
     bigram_plot <-  bigram_plot %>% 
        layout(title = "Fifteen Most Frequent Race Bigrams",
         xaxis = list(title = "Number of Bigrams"),
         yaxis = list(title = "Bigrams")
     )

bigram_plot

```

